myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue", "blue3", "blue4", "blueviolet", "brown1", "brown2",
"brown3", "darkgoldenrod3", "darkgoldenrod4",
"chocolate2", "chocolate3", "chocolate1", "chartreuse3",
"chartreuse3", "coral2", "coral3", "coral4","cornflowerblue",
"darkmagenta", "darkorchid2", "darkorchid3", "darkorchid4",
"deepskyblue2", "deepskyblue3", "deepskyblue4", "dodgerblue4", "dodgerblue3", "dodgerblue2",
"firebrick1", "firebrick2", "firebrick3","lightslateblue",
"purple", "purple1", "purple2", "purple3", "purple4", "red", "red1",
"red2", "red3", "red4", "turquoise4", "turquoise2", "violetred1",
"violetred2", "violetred3", "violetred4")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.5), colors = sample(color, 20, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue", "blue3", "blue4", "blueviolet", "brown1", "brown2",
"brown3", "darkgoldenrod3", "darkgoldenrod4",
"chocolate2", "chocolate3", "chocolate1", "chartreuse3",
"chartreuse3","cornflowerblue", "darkorchid2", "darkorchid3", "darkorchid4",
"deepskyblue2", "deepskyblue3", "deepskyblue4", "dodgerblue4", "dodgerblue3", "dodgerblue2",
"firebrick1", "firebrick2", "firebrick3","lightslateblue",
"purple", "purple1", "purple2", "purple3", "purple4", "red", "red1",
"red2", "red3", "red4", "turquoise4", "turquoise2", "violetred1",
"violetred2", "violetred3", "violetred4")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.5), colors = sample(color, 20, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "blueviolet", "brown1", "brown2",
"brown3", "darkgoldenrod3", "darkgoldenrod4",
"chocolate2", "chocolate3", "chocolate1", "chartreuse3",
"chartreuse3","cornflowerblue", "darkorchid2", "darkorchid3", "darkorchid4",
"deepskyblue2", "deepskyblue3", "deepskyblue4", "dodgerblue4", "dodgerblue3", "dodgerblue2",
"firebrick1", "firebrick2", "firebrick3","lightslateblue",
"purple", "purple1", "purple2", "purple3", "purple4", "red", "red1",
"red2", "red3", "red4", "turquoise4", "turquoise2", "violetred1",
"violetred2", "violetred3", "violetred4")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.5), colors = sample(color, 20, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "blueviolet", "brown1", "brown2",
"brown3", "darkgoldenrod3", "darkgoldenrod4",
"chocolate2", "chocolate3", "chocolate1", "chartreuse3",
"chartreuse3","darkorchid2", "darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3","lightslateblue",
"purple", "purple1", "purple2", "purple3", "purple4", "red", "red1",
"red2", "red3", "red4", "turquoise4", "turquoise2", "violetred1",
"violetred2", "violetred3", "violetred4")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.5), colors = sample(color, 20, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "blueviolet", "brown1", "brown2",
"brown3", "darkgoldenrod3", "darkgoldenrod4",
"chocolate2", "chocolate3", "chocolate1", "chartreuse3",
"chartreuse3","darkorchid2", "darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple", "purple1", "purple2", "purple3", "purple4", "red", "red1",
"red2", "red3", "red4", "turquoise4", "turquoise2", "violetred1",
"violetred2", "violetred3", "violetred4")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.5), colors = sample(color, 20, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "blueviolet", "brown1", "brown2",
"brown3", "darkgoldenrod3", "darkgoldenrod4",
"chocolate2", "chocolate3", "chocolate1", "chartreuse3",
"chartreuse3","darkorchid2", "darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple", "purple1", "purple2", "purple3", "purple4", "red", "red1",
"red2", "red3", "red4", "violetred1",
"violetred2", "violetred3", "violetred4")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.5), colors = sample(color, 20, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "blueviolet", "brown1", "brown2",
"brown3", "darkgoldenrod3", "darkgoldenrod4",
"chocolate2", "chocolate3", "chocolate1",
"green4","darkorchid2", "darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple", "purple1", "purple2", "purple3", "purple4", "red", "red1",
"red2", "red3", "red4", "violetred1",
"violetred2", "violetred3", "violetred4")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.5), colors = sample(color, 20, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "blueviolet", "brown1", "brown2",
"brown3", "darkgoldenrod3", "darkgoldenrod4",
"chocolate2", "chocolate3", "chocolate1",
"green4","darkorchid2", "darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple", "purple1", "purple2", "purple3", "purple4", "red", "red1",
"red2", "red3", "red4")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.5), colors = sample(color, 20, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "blueviolet", "brown1", "brown2",
"brown3", "darkgoldenrod3", "darkgoldenrod4",
"chocolate2", "chocolate3", "chocolate1",
"green4","darkorchid2", "darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple", "purple1", "purple2", "purple3", "purple4", "red", "red1",
"red2", "red3", "red4")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.5), colors = sample(color, 10, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "darkgoldenrod3", "darkgoldenrod4",
"chocolate1", "chocolate3", "chocolate1",
"green4","darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple3", "purple4")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.5), colors = sample(color, 15, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "darkgoldenrod3", "darkgoldenrod4",
"chocolate1", "chocolate3", "chocolate1",
"green4","darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple3")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.5), colors = sample(color, 15, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "darkgoldenrod3", "darkgoldenrod4",
"chocolate1", "chocolate3", "chocolate1",
"green4","darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple3")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(1.9,.5), colors = sample(color, 15, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "darkgoldenrod3", "darkgoldenrod4",
"chocolate1", "chocolate3", "chocolate1",
"green4","darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple3")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(3,1), colors = sample(color, 15, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "darkgoldenrod3", "darkgoldenrod4",
"chocolate1", "chocolate3", "chocolate1",
"green4","darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple3")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(3.5,1), colors = sample(color, 15, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "darkgoldenrod3", "darkgoldenrod4",
"chocolate1", "chocolate3", "chocolate1",
"green4","darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple3")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2,1), colors = sample(color, 15, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "darkgoldenrod3", "darkgoldenrod4",
"chocolate1", "chocolate3", "chocolate1",
"green4","darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple3")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2,.9), colors = sample(color, 15, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "darkgoldenrod3", "darkgoldenrod4",
"chocolate1", "chocolate3", "chocolate1",
"green4","darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple3")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(2.2,.9), colors = sample(color, 15, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
keywords <- c("venom", "snake", "snakebite", "antisnake")
myCorpus <- Corpus(VectorSource(snakebite$Text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, keywords)
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "\\<nm\\>", replacement = "n8m")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "[^[:alnum:][:blank:]?&/\\-]", replacement = "")))
myCorpus <- tm_map(myCorpus, content_transformer(function(x) gsub(x, pattern = "u00..", replacement = "")))
myCorpus <- iconv(myCorpus, from = "UTF-8", to = "ASCII", sub = "")  ## removing non asci charatcers
token_delim <- " \\t\\r\\n.!?,;\"()"
bitoken <- NGramTokenizer(myCorpus, Weka_control(min=2,max=2, delimiters = token_delim))
two_word <- data.frame(table(bitoken))
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
head(sort_two, 20)
color <- c("blue3", "blue4", "darkgoldenrod3", "darkgoldenrod4",
"chocolate1", "chocolate3", "chocolate1",
"green4","darkorchid3", "darkorchid4",
"firebrick1", "firebrick2", "firebrick3",
"purple3")
set.seed(4363)
wordcloud(sort_two$bitoken,sort_two$Freq,random.order=FALSE,min.freq = 20, scale=c(1.9,.9), colors = sample(color, 15, replace=TRUE ))
ggplot(head(sort_two,30), aes(reorder(bitoken,Freq), Freq)) +
geom_bar(stat = "identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
